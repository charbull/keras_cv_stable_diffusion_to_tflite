{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53ef16-9441-427e-aa27-afe6f83c7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffa7b3-95fb-4d05-9aad-bc2fb01ff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pipeline, then get the diffusion/denoise mode\n",
    "\n",
    "model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)\n",
    "diffusion_model = model.diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc3869-cf43-4600-8460-b907c57f819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the op/layer that we can use to split the model into two roughly equal chunks\n",
    "\n",
    "def find_split_layer(model):\n",
    "    total_size = 0\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if layer.weights:\n",
    "            # print(layer.name)\n",
    "            if (isinstance(layer.weights, list)):\n",
    "                  for w in layer.weights:\n",
    "                    # print(w.shape, w.dtype)\n",
    "                    total_size = total_size + w.numpy().size\n",
    "    # print(\"total size:\", total_size)\n",
    "    half_size = total_size / 2\n",
    "\n",
    "    first_layers = []\n",
    "    accumulator = 0 \n",
    "    for layer in model.layers:\n",
    "        first_layers.append(layer.name)\n",
    "        # print(first_layers)\n",
    "        if layer.weights:\n",
    "            if (isinstance(layer.weights, list)):\n",
    "                for w in layer.weights:\n",
    "                    accumulator = accumulator + w.numpy().size\n",
    "                if accumulator > half_size:\n",
    "                    return first_layers, layer.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the edges crossing both chunks\n",
    "# use them as the output tensors of the first chunk and the input tensors of the second chunk\n",
    "\n",
    "def find_boundary_tensors(model, first_layers, end_of_first_chunk):\n",
    "    \n",
    "    boundary_tensors = []\n",
    "    boundary_input_layers = []\n",
    "    in_second_chunk = False\n",
    "    \n",
    "    for l in model.layers:\n",
    "        if in_second_chunk:\n",
    "            #print(l.name)\n",
    "            if (isinstance(l.input, list)):\n",
    "                for i in l.input:\n",
    "                    #print(\"  \", i.node.layer.name)\n",
    "                    if (i.node.layer.name in first_layers):\n",
    "                        #print(\"  \", i.node.layer.name)\n",
    "                        #print(boundary_input_layers)\n",
    "                        if (i.node.layer.name not in boundary_input_layers):\n",
    "                            # print(boundary_tensors)\n",
    "                            boundary_tensors.append(i)\n",
    "                            boundary_input_layers.append(i.node.layer.name)\n",
    "            else:\n",
    "                # print(\"  whatever\", l.input.node.layer.name)\n",
    "                if (l.input.node.layer.name in first_layers):\n",
    "                    # print(\"  yes:\", l.input.layer.name)\n",
    "                    boundary_tensors.append(l.input)\n",
    "                    boundary_input_layers.append(i.input.name)\n",
    "                    \n",
    "        elif (l.name == end_of_first_chunk):\n",
    "            in_second_chunk = True\n",
    "            \n",
    "    return boundary_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93227d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layers, end_of_first_chunk = find_split_layer(diffusion_model)\n",
    "boundary_tensors = find_boundary_tensors(diffusion_model, first_layers, end_of_first_chunk)\n",
    "\n",
    "# construct the two chunks\n",
    "first_part = keras.Model(diffusion_model.inputs, boundary_tensors)\n",
    "second_part = keras.Model(boundary_tensors, diffusion_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f0a6e-f1aa-426b-9a3c-ff784848c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"A watercolor painting of a Golden Retriever at the beach\"\n",
    "encoding_1 = model.encode_text(prompt_1)\n",
    "\n",
    "def get_timestep_embedding(timestep, batch_size, dim=320, max_period=10000):\n",
    "    half = dim // 2\n",
    "    freqs = tf.math.exp(\n",
    "        -math.log(max_period) * tf.range(0, half, dtype=tf.float32) / half\n",
    "    )\n",
    "\n",
    "    args = tf.convert_to_tensor([timestep], dtype=tf.float32) * freqs\n",
    "    embedding = tf.concat([tf.math.cos(args), tf.math.sin(args)], 0)\n",
    "    embedding = tf.reshape(embedding, [1, -1])\n",
    "    return tf.repeat(embedding, batch_size, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b85b49-d7ea-4a1f-8a1c-5ddfbd20bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen_first():\n",
    "    for i in range(1):\n",
    "        em = get_timestep_embedding(i+1, 1) \n",
    "        noise = tf.random.normal((1, 64, 64, 4))\n",
    "    yield ({'input_1': encoding_1, 'input_2': em, 'input_3': noise})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f9057-1fed-4be0-a89a-989a463ace2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when converting a Keras model to a tflite model, it's saved to a saved_model first\n",
    "# in a saved_model, the 13 inputs are named args_0, args_0_1, args_0_2,..., args_0_12\n",
    "def representative_data_gen_second():\n",
    "    for i in range(1):\n",
    "        em = get_timestep_embedding(i+1, 1) \n",
    "        noise = tf.random.normal((1, 64, 64, 4))\n",
    "        a = first_part((noise, em, encoding_1))\n",
    "        yield ({\n",
    "            'args_0': a[0],\n",
    "            'args_0_1': a[1],\n",
    "            'args_0_2': a[2],\n",
    "            'args_0_3': a[3],\n",
    "            'args_0_4': a[4],\n",
    "            'args_0_5': a[5],\n",
    "            'args_0_6': a[6],\n",
    "            'args_0_7': a[7],\n",
    "            'args_0_8': a[8],\n",
    "            'args_0_9': a[9],\n",
    "            'args_0_10': a[10],\n",
    "            'args_0_11': a[11],\n",
    "            'args_0_12': a[12]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fe6b1-298a-471e-9a64-424567eb2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter1 = tf.lite.TFLiteConverter.from_keras_model(first_part)\n",
    "converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter1.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter1.inference_input_type = tf.int8\n",
    "converter1.inference_output_type = tf.int8\n",
    "\n",
    "converter1.representative_dataset = representative_data_gen_first\n",
    "first_chunk_qint8_tflite = converter1.convert()\n",
    "\n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(second_part)\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter2.inference_input_type = tf.int8\n",
    "converter2.inference_output_type = tf.int8\n",
    "\n",
    "converter2.representative_dataset = representative_data_gen_second\n",
    "second_chunk_qint8_tflite = converter2.convert()\n",
    "\n",
    "with open('/tmp/diffusion_model_first_qint8.tflite', 'wb') as f:\n",
    "        f.write(first_chunk_qint8_tflite)\n",
    "\n",
    "with open('/tmp/diffusion_model_second_qint8.tflite', 'wb') as f:\n",
    "        f.write(second_chunk_qint8_tflite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
