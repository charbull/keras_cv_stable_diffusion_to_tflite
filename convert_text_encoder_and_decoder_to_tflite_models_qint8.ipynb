{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53ef16-9441-427e-aa27-afe6f83c7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffa7b3-95fb-4d05-9aad-bc2fb01ff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pipeline, get text_encoder and decoder\n",
    "\n",
    "model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "text_encoder_model = model.text_encoder\n",
    "decoder_model = model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2f884-4371-43de-b0a0-51bdb4363d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PROMPT_LENGTH = 77\n",
    "\n",
    "def get_pos_ids():\n",
    "    return tf.convert_to_tensor([list(range(MAX_PROMPT_LENGTH))], dtype=tf.int32)\n",
    "\n",
    "def representative_data_gen_text_encoder():\n",
    "    for i in range(1):\n",
    "        inputs = tokenizer.encode('This is a test')\n",
    "        phrase = inputs + [49407] * (MAX_PROMPT_LENGTH - len(inputs))\n",
    "        phrase = tf.convert_to_tensor([phrase], dtype=tf.int32)\n",
    "\n",
    "        yield [phrase, get_pos_ids()]\n",
    "        \n",
    "def representative_data_gen_decoder():\n",
    "    for i in range(1):\n",
    "        noise = tf.random.normal((1, 64, 64, 4))\n",
    "        yield [noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the two models to tflite\n",
    "\n",
    "converter1 = tf.lite.TFLiteConverter.from_keras_model(text_encoder_model)\n",
    "converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter1.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# new quantizer cannot handle text_encoder (yet)\n",
    "converter1.experimental_new_quantizer = False\n",
    "converter1.representative_dataset = representative_data_gen_text_encoder\n",
    "tflite_text_encoder_qint8 = converter1.convert()\n",
    "\n",
    "with open('/tmp/sd_text_encoder_qint8.tflite', 'wb') as f:\n",
    "    f.write(tflite_text_encoder_qint8)\n",
    "    \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(decoder_model)\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter2.representative_dataset = representative_data_gen_decoder\n",
    "tflite_decoder_qint8 = converter2.convert()\n",
    "    \n",
    "with open('/tmp/sd_decoder_qint8.tflite', 'wb') as f:\n",
    "    f.write(tflite_decoder_qint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
